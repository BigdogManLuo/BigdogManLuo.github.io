<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: Articles - Try to Understand</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Try to Understand"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Try to Understand"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Try to Understand"><meta property="og:url" content="https://bigdogmanluo.github.io/"><meta property="og:site_name" content="Try to Understand"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://bigdogmanluo.github.io/img/og_image.png"><meta property="article:author" content="BigdogManLuo"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://bigdogmanluo.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://bigdogmanluo.github.io"},"headline":"Try to Understand","image":["https://bigdogmanluo.github.io/img/og_image.png"],"author":{"@type":"Person","name":"BigdogManLuo"},"publisher":{"@type":"Organization","name":"Try to Understand","logo":{"@type":"ImageObject","url":"https://bigdogmanluo.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Try to Understand" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/BigdogManLuo"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories/">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Articles</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-08-05T23:00:00.000Z" title="2025/8/6 00:00:00">2025-08-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T21:41:37.179Z" title="2025/8/27 22:41:37">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Articles/">Articles</a></span><span class="level-item">6 minutes read (About 960 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/08/06/thoughts-AIGC/">论 AIGC 的&quot;图腾&quot;</a></p><div class="content"><p>当前 AIGC 已经可以做到以假乱真的程度，例如用 AI P 图来骗取网购退款等等案例。可预见的未来有一天，不管是照片、音频还是视频，都无法作为法庭上客观的证据呈现了。</p>
<h2 id="强制的暗水印">强制的暗水印</h2>
<p>关键在于如何辨别 AI 产生或者处理过的内容。对于可以公开被访问的 AI 模型，可以强制其生成内容中带有暗水印，不会影响视觉，但实现了保留一个接口供外部可直接鉴定。当然，也会相应的仿暗水印技术将真实内容伪造为 AI 内容。虽不能以假乱真，但也提供了一个途径将真变为“假”。不过用非对称加密应该可以解决这一点。但即便这个强制措施可以治理市面上可公开访问模型，但仍然无法避免私有的 AI 模型做伪，毕竟技术永远都是一把双刃剑。</p>
<h2 id="图腾">图腾</h2>
<p>除了暗水印这种治标的方法，是否还有技术够直接检测 AIGC？一次在梦中的灵感，联想到盗梦空间中的“图腾”，陀螺停下来就代表身处现实世界，而陀螺一直不停转则代表处于梦中。<strong>这是因为现实世界里根本不存在一直不停转的陀螺。</strong> 所以关键在于物理规律。如果一个视频有效，那么它应该包含有可被检测的”图腾“。对于视频领域，符合物理规律的运动往往要通过物理引擎进行渲染。尤其是对于流体的模拟，则需要花费大量时间和计算成本去做数值仿真（且由于混沌特性，流体的数值计算也可能与实际的情况也存在大出入）。而真实世界的运动是通过真实的物理”引擎“渲染出来的，自然发生的。即便回到物理引擎的模拟，也与现有的 diffusion model 这类的 GAI 范式有着本质的区别。一个是 model-based 计算，一个是 data-driven 式的扩散。目前很难在生成式的神经网络模型中直接添加一个硬物理约束，更何况是复杂的无数条物理定律。所以，要想证明一个真实世界的视频，而不是 AI 产生的，或许只需要在视频里出现那些符合物理规律的运动。我想这就是 AIGC 的“图腾”吧。当然，这仅限于视频，而类似于图片，音频这样的内容可能还需要继续寻找“图腾”。但我认为，不管如何，这个“图腾”应该符合的核心原理是：</p>
<ul>
<li>在真实世界中很容易产生的</li>
<li>在计算世界里需要耗费大量成本和时间才能模拟出来（但始终不是真实世界完全一致的）</li>
<li>但是可以通过有限的成本可以被检测出来的 (类似于hash函数这样的单向通道)</li>
</ul>
<p>当然，理想的图腾还是难以寻找。不管是暗水印还是“图腾”，其核心目的都是为了增加造假的成本。只不过暗水印无法杜绝根本，而“图腾”则是利用了 GAI 范式与现实世界中本质的区别。AI 应用治理规范已经迫在眉睫，但仍然有很长的路要走。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-03-06T00:00:00.000Z" title="2023/3/6 00:00:00">2023-03-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T21:41:30.771Z" title="2025/8/27 22:41:30">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Articles/">Articles</a></span><span class="level-item">15 minutes read (About 2324 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/03/06/techArt-Code_acc/">Accelerating Your Program Through Coding Skills</a></p><div class="content"><h1>Introduction</h1>
<p>When dealing with large-scale, complex optimization problems or training neural networks, we often encounter situations where programs run for extended periods or fail to complete. However, this is not necessarily due to the large problem scale or limitations of computer hardware capabilities. Even when attempting to use higher-performance servers or computers, there’s no guarantee of effectively accelerating code execution. This is because high-performance hardware typically needs to be matched with code designed for high-performance computing.</p>
<p>This article aims to provide some code-level optimization strategies for program acceleration. By optimizing code structure and designing high-performance computing solutions, we can effectively accelerate program execution and improve runtime efficiency. It’s important to note that this article only covers code-level acceleration solutions and does not include optimization measures related to algorithms, hardware, etc. The article is written based on personal experience, and if there are any shortcomings, please point them out.</p>
<h1>Code Optimization</h1>
<p>Simply put, there are mainly two approaches to implementing program optimization. One is to parallelize tasks and write parallel code to leverage the parallel computing capabilities of multi-core CPUs or GPUs to accelerate program execution. The other is to utilize compiler code optimization mechanisms to compile parts of code that require interpreters (such as Python, MATLAB) into machine code, achieving faster program execution speeds.</p>
<h2 id="1-Parallelization">1 Parallelization</h2>
<p>Parallelization requires coordination between software and hardware, but the prerequisite is that the overall task can be decomposed into subtasks that can be executed simultaneously. There are two ways to achieve parallelization: one relies on multi-core CPUs to implement multi-process operations, and the other relies on GPUs. We will introduce the implementation methods of these two approaches below.</p>
<h3 id="1-1-CPU-Multi-process-Operations">1.1 CPU Multi-process Operations</h3>
<p>Multi-process operations leverage the multi-core characteristics of CPUs to achieve parallel computing. In multi-process operations, programs are decomposed into multiple subtasks, each running in an independent process. These processes can execute different tasks in parallel, thereby accelerating program execution. Multi-process operations can be implemented using Python’s multiprocessing library.</p>
<p>When using the multiprocessing library for multi-process operations, it’s first necessary to decompose tasks into multiple subtasks and assign each subtask to different processes for execution.</p>
<p>The following is a code framework for the multiprocessing library:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">worker</span>(<span class="params">num</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Worker <span class="subst">&#123;num&#125;</span> is running&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    processes = []</span><br><span class="line">    num_processes = <span class="number">4</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_processes):</span><br><span class="line">        p = multiprocessing.Process(target=worker, args=(i,))</span><br><span class="line">        processes.append(p)</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">        p.join()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;All workers are done&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>In this example, we first define a <code>worker</code> function, which is the task that each subprocess will execute. Then in the main process (if <strong>name</strong>==“<strong>main</strong>”), we create <code>num_processes</code> subprocesses and add them to the <code>processes</code> list. Next, we iterate through the <code>processes</code> list, use the start() method from the Process class to start each subprocess, and wait for them to complete. Finally, we output “All workers are done” to indicate that all subprocesses have finished execution.</p>
<h3 id="1-2-GPU">1.2 GPU</h3>
<p>Compared to CPUs, GPUs have more computing cores and higher computational power, making them better suited for parallel computing. Therefore, utilizing GPUs for code optimization can significantly improve program execution efficiency. To use GPUs for code optimization in Python, GPU programming frameworks such as NVIDIA’s CUDA framework are commonly used.</p>
<h4 id="1-2-1-Python-Implementation-of-GPU-Parallel-Computing">1.2.1 Python Implementation of GPU Parallel Computing</h4>
<p>CUDA, developed by NVIDIA, is a GPU programming framework that allows developers to leverage the parallel computing capabilities of GPUs to accelerate various compute-intensive tasks. CUDA provides a set of APIs that facilitate GPU programming and supports multiple programming languages, including C/C++, Python, and Java. When using CUDA, the CUDA toolkit, which includes the CUDA driver, runtime library, and tools, is required.</p>
<p>The following is a simple example of vector addition using the CUDA framework:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numba <span class="keyword">import</span> cuda</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the vector addition function</span></span><br><span class="line"><span class="meta">@cuda.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vector_add</span>(<span class="params">a, b, c</span>):</span><br><span class="line">    i = cuda.grid(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(c):</span><br><span class="line">        c[i] = a[i] + b[i]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the main program</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># Define the vector size</span></span><br><span class="line">    n = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Generate random vectors on the host</span></span><br><span class="line">    a = np.random.randn(n).astype(np.float32)</span><br><span class="line">    b = np.random.randn(n).astype(np.float32)</span><br><span class="line">    c = np.zeros(n, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Transfer data to GPU memory</span></span><br><span class="line">    d_a = cuda.to_device(a)</span><br><span class="line">    d_b = cuda.to_device(b)</span><br><span class="line">    d_c = cuda.to_device(c)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define thread blocks and the number of threads</span></span><br><span class="line">    threads_per_block = <span class="number">64</span></span><br><span class="line">    blocks_per_grid = (n + (threads_per_block - <span class="number">1</span>)) // threads_per_block</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Perform the vector addition operation</span></span><br><span class="line">    vector_add[blocks_per_grid, threads_per_block](d_a, d_b, d_c)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Transfer the result from GPU memory back to host memory</span></span><br><span class="line">    d_c.copy_to_host(c)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print the result</span></span><br><span class="line">    <span class="built_in">print</span>(c)</span><br></pre></td></tr></table></figure>
<p>In the above code, we first define a <code>vector_add</code> function to add two vectors and store the result in a third vector. Then we generate two random vectors and transfer them to GPU memory. Next, we define thread blocks and the number of threads. In the GPU section, we need to pay attention to vectorization, i.e., writing code that utilizes matrix operations rather than serial computations with multiple for loops.</p>
<h4 id="1-2-2-Using-GPU-to-Train-Neural-Networks">1.2.2 Using GPU to Train Neural Networks</h4>
<p>When it comes to training deep neural networks, GPUs can demonstrate their advantages, as training neural networks often requires a large number of matrix operations, which is precisely the task GPUs excel at.</p>
<p>Here is a simple example of neural network training code based on PyTorch and CUDA:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the neural network model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(F.relu(<span class="variable language_">self</span>.conv1(x)))</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(F.relu(<span class="variable language_">self</span>.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc1(x))</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc2(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the training data and labels</span></span><br><span class="line">inputs = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">labels = torch.randn(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Move the neural network model to GPU</span></span><br><span class="line">net = Net().cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Move the training data and labels to GPU</span></span><br><span class="line">inputs = inputs.cuda()</span><br><span class="line">labels = labels.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the loss function and optimizer</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    outputs = net(inputs)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch %d, Loss: %.4f&#x27;</span> % (epoch+<span class="number">1</span>, loss.item()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>In the above code, we use the <code>xxx.cuda()</code> method to load the model, training data, and labels into GPU memory, so that all computations involved in the training loop are carried out on the GPU.</p>
<h4 id="1-2-3-Precautions">1.2.3 Precautions</h4>
<p>It’s particularly important to note that if you want to use a GPU for acceleration, you must ensure that the code is vectorized. Simply put, try to use matrix operations to represent the numerical computation process instead of using multiple for loops in a nested manner.</p>
<p>This is because GPUs, compared to CPUs, are only stronger in terms of parallelism, but their computational power is inferior to that of CPUs. Serial computations like multiple for loops are not suitable for GPUs. To put it in the words of Dr. Li Mu, if a CPU is like a college student, a GPU is like a group of elementary school students. A college student can handle tasks like calculus, while elementary school students can only handle basic arithmetic. However, if a calculus task is broken down into multiple basic arithmetic operations, then the advantage of a group of elementary students, i.e., the GPU, becomes apparent.</p>
<p>To give a simple example, suppose we want to design a loss function like this:
$$L_\theta=-\sum_{i=1}^{N}\sum_{j=1}^{N_i}w_{ij}log(p(x_i^j|M))$$
If we don’t deliberately pay attention to the vectorization of the code, a common-sense approach might look like this:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lossFunc</span>(<span class="params">y_pred,sols,objs</span>):</span><br><span class="line">batch size=y_pred.shape[<span class="number">0</span>]</span><br><span class="line">loss=torch.tensor(<span class="number">0.0</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">	nSols=sols[i].shape[<span class="number">0</span>] <span class="comment">#Number of feasible solutions under the current batch (MIP)</span></span><br><span class="line">	nVars=sols[i].shape[<span class="number">1</span>]</span><br><span class="line">	<span class="comment">#Objective function normalization</span></span><br><span class="line">	den=objs[i].<span class="built_in">sum</span>()</span><br><span class="line">	<span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(objs[i].shape[<span class="number">0</span>]):</span><br><span class="line">		objs[i][l]=objs[i][l]/den</span><br><span class="line">	den=<span class="built_in">sum</span>(exp(-objs[i]))<span class="comment">#Calculate the denominator for wii coefficient</span></span><br><span class="line">	sum1=torch.tensor(<span class="number">0.0</span>)</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(nSols):</span><br><span class="line">		<span class="comment">#Calculate weight wij</span></span><br><span class="line">		w=exp(-objs[il[j])/den</span><br><span class="line">		<span class="comment">#Calculate the probability of feasible solution generation</span></span><br><span class="line">		P=torch.tensor(<span class="number">1.9</span>)</span><br><span class="line">		<span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(nVars):</span><br><span class="line">			<span class="keyword">if</span> sols[il[j,k]==<span class="number">1</span>:</span><br><span class="line">				P=p*y_pred[i][k]</span><br><span class="line">			<span class="keyword">elif</span> sols[il[j,k]==<span class="number">0</span>:</span><br><span class="line">				P=p*(<span class="number">1</span>-y_pred[i][k])</span><br><span class="line">		<span class="comment">#Calculate the summation</span></span><br><span class="line">		sum1+=w*p</span><br><span class="line">	loss+=sum1</span><br><span class="line">loss=-loss</span><br><span class="line"><span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<p>But in reality, a loss function designed with multiple nested for loops is not suitable for GPU execution and may even perform worse than on a CPU. Test results showed that with such a loss function, one epoch would take about an hour… making it impossible to train the neural network.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lossFunc</span>(<span class="params">y,sols,objs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Loss function</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    y : Neural network output batch_size x nVars</span></span><br><span class="line"><span class="string">    sols : Set of feasible solutions batch_size x nSols x nVars</span></span><br><span class="line"><span class="string">    objs : Objective function values corresponding to feasible solutions batch_size x nSols</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    loss : Loss on the current batch</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    objs=objs/<span class="number">15</span></span><br><span class="line">    eObjs=exp(-objs)</span><br><span class="line">    den=eObjs.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">    den=den.unsqueeze(<span class="number">1</span>)</span><br><span class="line">    w=eObjs/den</span><br><span class="line">    y=y.unsqueeze(<span class="number">1</span>)</span><br><span class="line">    p=y*sols+(<span class="number">1</span>-y)*(<span class="number">1</span>-sols)</span><br><span class="line">    p=log(p+<span class="number">1e-45</span>)</span><br><span class="line">    P=p.<span class="built_in">sum</span>(axis=<span class="number">2</span>)</span><br><span class="line">    loss=-(w*P).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<p>So the correct approach should be like this, which not only shows significant acceleration on the GPU but also looks much cleaner… The downside is that you have to constantly use the broadcasting mechanism of matrix operations and it’s best to hand-calculate a few times with small-scale examples, calculating while designing.</p>
<h2 id="2-Compiler-Acceleration">2 Compiler Acceleration</h2>
<h3 id="2-1-Principles">2.1 Principles</h3>
<p>In computer programming, compiled languages and interpreted languages are two common types. Compared to interpreted languages, compiled languages execute faster because they need to compile the code into executable binary code before execution. This is because compilers can optimize the source code into more efficient machine code, thereby speeding up program execution.</p>
<p>There are many ways for compiler optimization, among which the most common include:</p>
<ol>
<li>
<p>Eliminating unnecessary calculations: Compilers can identify unnecessary calculations during code compilation, avoiding waste of computational resources.</p>
</li>
<li>
<p>Loop unrolling: Loop unrolling refers to the practice of repeating the code in the loop body several times to reduce the number of loop iterations. This can improve the program’s running speed.</p>
</li>
<li>
<p>Matrix/Vectorization: Matrix/Vectorization refers to placing multiple data into a matrix or vector and then performing calculations all at once. This can reduce the number of loop iterations and thus improve the program’s running speed.</p>
</li>
</ol>
<p>To help developers conveniently utilize compiler optimization for code, some open-source JIT compilers like Numba have been developed. These compilers can convert Python and other interpreted language codes into executable machine code, thus improving program execution speed.</p>
<h3 id="2-2-Python-Acceleration-Solution-Based-on-Numba">2.2 Python Acceleration Solution Based on Numba</h3>
<p>Numba is an open-source JIT compiler that can convert Python code into machine code, achieving code acceleration. Numba supports various optimization techniques, including loop unrolling, code vectorization, etc. Using Numba can greatly increase the execution speed of Python code.</p>
<p>The following is a general code framework for using Numba to achieve Python code acceleration:</p>
<ol>
<li>Import the numba library</li>
<li>Define a function that needs optimization</li>
<li>Use the @numba.jit decorator to decorate the function, generating the numba-optimized function</li>
<li>Call the optimized function</li>
</ol>
<p>To illustrate, let’s consider a comparative case that involves a deeply nested for loop to compute the determinant of a matrix. This is a compute-intensive operation that can benefit from acceleration using Numba.</p>
<p>Original Python code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">det</span>(<span class="params">matrix</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(matrix)</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> matrix[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">elif</span> n == <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> matrix[<span class="number">0</span>][<span class="number">0</span>] * matrix[<span class="number">1</span>][<span class="number">1</span>] - matrix[<span class="number">0</span>][<span class="number">1</span>] * matrix[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            sub_matrix = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">                row = []</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                    <span class="keyword">if</span> k != j:</span><br><span class="line">                        row.append(matrix[i][k])</span><br><span class="line">                sub_matrix.append(row)</span><br><span class="line">            result += matrix[<span class="number">0</span>][j] * det(sub_matrix) * (-<span class="number">1</span>) ** j</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>As we can see, this function contains deeply nested for loops, which are severely limited by the performance of the Python interpreter. Now let’s use Numba to accelerate it.</p>
<p>Optimized Numba code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numba</span><br><span class="line"></span><br><span class="line"><span class="meta">@numba.jit(<span class="params">nopython=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">det</span>(<span class="params">matrix</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(matrix)</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> matrix[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">elif</span> n == <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> matrix[<span class="number">0</span>][<span class="number">0</span>] * matrix[<span class="number">1</span>][<span class="number">1</span>] - matrix[<span class="number">0</span>][<span class="number">1</span>] * matrix[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            sub_matrix = np.zeros((n-<span class="number">1</span>, n-<span class="number">1</span>))</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                    <span class="keyword">if</span> k != j:</span><br><span class="line">                        sub_matrix[i-<span class="number">1</span>, k-(k&gt;j)] = matrix[i, k]</span><br><span class="line">            result += matrix[<span class="number">0</span>][j] * det(sub_matrix) * (-<span class="number">1</span>) ** j</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Here, we use the <code>@numba.jit(nopython=True)</code> decorator to declare the function as one that can be accelerated by Numba. Simultaneously, we replace Python lists with Numpy arrays and use Numpy array slicing and broadcasting features to reduce loops and memory allocation.</p>
<p>Testing code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate a random 10x10 matrix</span></span><br><span class="line">matrix = np.random.rand(<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Time the original Python code</span></span><br><span class="line">start = time.time()</span><br><span class="line">d = det(matrix)</span><br><span class="line">end = time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Python code took <span class="subst">&#123;end-start:<span class="number">.4</span>f&#125;</span> seconds, result=<span class="subst">&#123;d&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Time the Numba-optimized code</span></span><br><span class="line">start = time.time()</span><br><span class="line">d = det(matrix)</span><br><span class="line">end = time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Numba-optimized code took <span class="subst">&#123;end-start:<span class="number">.4</span>f&#125;</span> seconds, result=<span class="subst">&#123;d&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>Testing results:</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Python <span class="selector-tag">code</span> took <span class="number">0.5960</span> seconds, result=-<span class="number">0.004127521725273144</span></span><br><span class="line">Numba-optimized <span class="selector-tag">code</span> took <span class="number">0.0040</span> seconds, result=-<span class="number">0.004127521725273144</span></span><br></pre></td></tr></table></figure>
<p>It’s important to note that Numba is not almighty, and there are certain limitations to the types of code it can accelerate. If the function decorated with the decorator is nested with many functions from third-party libraries, Numba may not be able to work.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-04-14T23:00:00.000Z" title="2022/4/15 00:00:00">2022-04-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-08-27T21:41:24.724Z" title="2025/8/27 22:41:24">2025-08-27</time></span><span class="level-item"><a class="link-muted" href="/categories/Articles/">Articles</a></span><span class="level-item">14 minutes read (About 2055 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/04/15/techArt-AutoEmail/">裁缝式开发：用MATLAB批量发送一封图文并茂的邮件</a></p><div class="content"><h1>问题背景</h1>
<p>前几天，女朋友公司要求她周末加班发送宣传推广邮件给高校老师，而我才知晓之前她们发送邮件全靠手动…目前待发名单至少有三千人，而现在才发了一百多封，我的心情如下</p>
<p><img src="/2022/04/15/techArt-AutoEmail/p1.png" alt></p>
<p>为了能够不加班周末去放风筝，于是我决定亲自动手。但是毕竟我不是搞Web开发的，应该从哪下手呢？<strong>答案是：面向百度编程。</strong></p>
<h1>实现过程</h1>
<h2 id="组装轮子——MATLAB如何发送一封图文并茂的邮件？">组装轮子——MATLAB如何发送一封图文并茂的邮件？</h2>
<h3 id="1-发送一封普通的邮件">1.发送一封普通的邮件</h3>
<p>MathWorks 在官方文档里提供了sendmail函数用于向指定的地址列表发送电子邮件<br>
<img src="/2022/04/15/techArt-AutoEmail/p2.png" alt></p>
<p>需要设置的参数如下：<br>
发件人邮箱地址、发件人邮箱授权码（注意不是密码，而是邮箱用于登录第三方邮件客户端的专用密码）、SMTP服务器地址、收件人邮箱、主题、内容、附件</p>
<p>详细请见：<a target="_blank" rel="noopener" href="https://ww2.mathworks.cn/help/matlab/ref/sendmail.html?searchHighlight=sendmail&amp;s_tid=srchtitle_sendmail_1%EF%BC%88MathWorks%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%EF%BC%89">https://ww2.mathworks.cn/help/matlab/ref/sendmail.html?searchHighlight=sendmail&amp;s_tid=srchtitle_sendmail_1（MathWorks官方文档）</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/eswai/article/details/53454987%EF%BC%88%E4%BD%BF%E7%94%A8%E4%BE%8B%E7%A8%8B%EF%BC%89">https://blog.csdn.net/eswai/article/details/53454987（使用例程）</a></p>
<h3 id="2-发送html格式的邮件">2.发送html格式的邮件</h3>
<p>mathworks官方给出的sendmail函数虽然能够实现自动发送邮件，但有个致命的缺点是，它只能支持普通文本，并不能发送html格式，因此排版、字号、颜色等参数统统都不能实现。距离我们的目标还有一段距离。
<img src="/2022/04/15/techArt-AutoEmail/p3.png" alt>
经过互联网的大海捞针，终于找到这样一篇帖子，有位老哥提出来可以修改sendmail的库函数实现发送html邮件。（<a target="_blank" rel="noopener" href="https://undocumentedmatlab.com/articles/sending-html-emails-from-matlab%EF%BC%89%E7%BF%BB%E8%AF%91%E8%BF%87%E6%9D%A5%E4%B8%BB%E8%A6%81%E6%9C%89%E4%B8%A4%E7%82%B9%EF%BC%9A">https://undocumentedmatlab.com/articles/sending-html-emails-from-matlab）翻译过来主要有两点：</a>
<strong>1.HTML 格式需要调用消息对象的 setContent（） 方法，而不是 setText（） <br>
2. 我们需要指定为消息编码的一部分’text/html’ <br></strong>
当然，为了避免重复造轮子，我们选择直接白嫖（狗头）
<img src="/2022/04/15/techArt-AutoEmail/p4.png" alt></p>
<h3 id="3-如何写html？">3.如何写html？</h3>
<p>那么问题又来了，虽然我们知道可以通过html格式发送一封排版整齐，图文并茂的邮件，可是对于小白来说，要想通过html书写邮件并不是一件容易的事情。但是我们可以换个思路，<strong>将文本内容转换为html。</strong>
直接检索文本转html，会发现有许多在线工具，支持txt,docx等格式。
<img src="/2022/04/15/techArt-AutoEmail/p5.png" alt>
打开转换好的xxx.html文件后，按Ctrl+U进入网页后台，就可以看到文本对应的html代码了。</p>
<h3 id="4-发送图片">4.发送图片</h3>
<p>那么问题又来了，假如我们的邮件中带有图片内容，又不想通过附件的方式发送，而是嵌入到邮件中，通过文本转换的方式能够生成图片的html代码吗？答案是可以的，但是生成的代码是图片的链接，在发送邮件之后，邮件系统往往会屏蔽掉图片链接，从而图片无法显示。针对此问题，一般可以通过“CID内嵌图像”方式完成。</p>
<blockquote>
<p>CID 的工作原理是将图像附加到要发送的电子邮件中，然后使用引用该图像的标准 HTML图像标记，以便在用户打开该图像时最终将其嵌入到电子邮件中。</p>
</blockquote>
<p>但是由于该方法同样涉及到需要改动sendmail库函数及其调用的java类软件包，因此对图像命名cid标签指向附件的方式较为复杂，CSDN中有大部分帖子是用python实现，未曾找到matlab方法。就在题主快要山穷水尽之时，又找到了这样一篇文章，里面提出可以<strong>将图片以base64编码的html代码进行邮件发送</strong>。
（<a target="_blank" rel="noopener" href="https://sendgrid.com/blog/embedding-images-emails-facts/%EF%BC%89">https://sendgrid.com/blog/embedding-images-emails-facts/）</a><br>
base64是一个字符集，图片在html中可以通过base64编码为字符串，而不用通过http请求。但是这样做的缺点是图片越大，base64的字符串就会越长，导致发送的html代码越长，对网络带宽要求也更高。
<img src="/2022/04/15/techArt-AutoEmail/p6.png" alt>
python和java中自带了将文件转码为base64的库函数，但由于一开始选错了路，所以就只能硬着头皮走到黑了。
于是，我又找到了图片转base64编码工具，手动解码，自此大功告成。
<img src="/2022/04/15/techArt-AutoEmail/p7.png" alt></p>
<h2 id="解放双手——实现批量操作">解放双手——实现批量操作</h2>
<p>我们最终的目的是为了实现内容相似，称呼不同的宣传推广邮件批量发送。现在终于可以开始施展拳脚了。
在配置好邮箱基本信息之后，读取一下待发送人员的名单，以变量receiverName和receiverEmail储存。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%接收者信息设置</span><br><span class="line">receiver=<span class="built_in">readcell</span>(<span class="string">&quot;xxxxx.xlsx&quot;</span>); %文件</span><br><span class="line">receiver=<span class="built_in">string</span>(receiver);</span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>:<span class="built_in">length</span>(receiver)<span class="number">-1</span></span><br><span class="line">    <span class="built_in">receiverName</span>(i,<span class="number">1</span>)=<span class="built_in">receiver</span>(i<span class="number">+1</span>,<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">receiverEmail</span>(i,<span class="number">1</span>)=<span class="built_in">receiver</span>(i<span class="number">+1</span>,<span class="number">2</span>);</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<p>紧接着设置主题和内容，其中函数strjoin可以实现，字符串拼接功能，用换行符分隔html代码，避免一行的代码过长，再统一根据据换行符拼接在一起。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mailcontent=<span class="built_in">strjoin</span>(&#123;</span><br><span class="line">  <span class="string">&#x27;&lt;html&gt;&#x27;</span></span><br><span class="line">  <span class="string">&#x27;&lt;body&gt;&#x27;</span></span><br><span class="line">  <span class="string">&#x27;&lt;h1&gt;Hello, World!&lt;/h1&gt;&#x27;</span></span><br><span class="line">  <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">  &#x27;</span>&lt;h2&gt;%s老师你好！&lt;/h2&gt;&#x27;</span><br><span class="line">  <span class="string">&#x27;&lt;img src=&quot;图片的base64编码&quot;&gt;&#x27;</span></span><br><span class="line">  <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">  &#x27;</span>&lt;/html&gt;&#x27;</span><br><span class="line">  <span class="string">&#x27;&lt;/body&gt;&#x27;</span></span><br><span class="line">  &#125;, <span class="string">&#x27;\n&#x27;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>sprintf函数可以实现字符替换的功能，在邮件内容的html代码中将称呼的地方改为%s 例如尊敬的%s老师，通过函数sprintf可以将%s处替换为变量receiverName(j)</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mailcontent=<span class="built_in">strjoin</span>(&#123;</span><br><span class="line">  <span class="string">&#x27;&lt;html&gt;&#x27;</span></span><br><span class="line">  <span class="string">&#x27;&lt;body&gt;&#x27;</span></span><br><span class="line">  <span class="string">&#x27;&lt;h1&gt;Hello, World!&lt;/h1&gt;&#x27;</span></span><br><span class="line">  <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">  &#x27;</span>&lt;h2&gt;%s老师你好！&lt;/h2&gt;&#x27;</span><br><span class="line">  <span class="string">&#x27;&lt;img src=&quot;图片的base64编码&quot;&gt;&#x27;</span></span><br><span class="line">  <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="string">  &#x27;</span>&lt;/html&gt;&#x27;</span><br><span class="line">  <span class="string">&#x27;&lt;/body&gt;&#x27;</span></span><br><span class="line">  &#125;, <span class="string">&#x27;\n&#x27;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>发送邮件：由于是批量发送，且数量一般较大，最好使用try…catch…的语法，当某一次因为邮箱信息错误、网络延迟等原因sendmail出现报错时能够跳过此次发送并记录下此次错误。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%发送邮件</span><br><span class="line">    <span class="function"><span class="keyword">try</span></span></span><br><span class="line"><span class="function">        <span class="title">sendmail_html</span><span class="params">(receiverEmail(j),mailtitle,mailcontent)</span></span>;</span><br><span class="line">    <span class="keyword">catch</span></span><br><span class="line">        error_count=error_count<span class="number">+1</span>;</span><br><span class="line">        <span class="built_in">error_index</span>(j)=<span class="string">&quot;failed&quot;</span>; %记录失败邮件的索引</span><br><span class="line">    end</span><br><span class="line">    count=count<span class="number">-1</span>;</span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>完整代码：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">%接收者信息设置</span><br><span class="line">error_count=<span class="number">0</span>;</span><br><span class="line">error_index=<span class="string">&quot;  &quot;</span>;</span><br><span class="line"></span><br><span class="line">receiver=<span class="built_in">readcell</span>(<span class="string">&quot;xxxxxx.xlsx&quot;</span>);</span><br><span class="line">receiver=<span class="built_in">string</span>(receiver);</span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>:<span class="built_in">length</span>(receiver)<span class="number">-1</span></span><br><span class="line">    <span class="built_in">receiverName</span>(i,<span class="number">1</span>)=<span class="built_in">receiver</span>(i<span class="number">+1</span>,<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">receiverEmail</span>(i,<span class="number">1</span>)=<span class="built_in">receiver</span>(i<span class="number">+1</span>,<span class="number">2</span>);</span><br><span class="line">end</span><br><span class="line">%主题</span><br><span class="line">mailtitle=<span class="string">&#x27;xxxxxxxxxxxxxxx&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j=<span class="number">1</span>:<span class="built_in">length</span>(receiverName)</span><br><span class="line">%正文</span><br><span class="line">mailcontent=<span class="built_in">sprintf</span>(<span class="built_in">strjoin</span>(&#123;</span><br><span class="line">%此处放入html代码 以换行符分隔 避免一行过长 </span><br><span class="line">%收件人昵称用%s代替</span><br><span class="line">&#125;，<span class="string">&quot;/n&quot;</span>),<span class="built_in">receiverName</span>(j))</span><br><span class="line"></span><br><span class="line">%发送邮件</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">        <span class="built_in">sendmail_html</span>(<span class="built_in">receiverEmail</span>(j),mailtitle,mailcontent);</span><br><span class="line">    <span class="keyword">catch</span></span><br><span class="line">        error_count=error_count<span class="number">+1</span>;</span><br><span class="line">        <span class="built_in">error_index</span>(j)=<span class="string">&quot;failed&quot;</span>; %记录失败邮件的索引</span><br><span class="line">    end</span><br><span class="line">    count=count<span class="number">-1</span>;</span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<h2 id="面向小白——UI交互">面向小白——UI交互</h2>
<p>既然都做到这了，那么就要面零基础的从业人员进行开发，设计交互界面，实现输入邮件名单自动发送并且可视化的功能，才是一款真正的产品。UI界面采用MATLAB AppDesigner进行设计。</p>
<p><img src="/2022/04/15/techArt-AutoEmail/p8.jpeg" alt></p>
<p>左上角为发件人设置界面，输入发件人信息进行邮箱授权码验证，成功后才可登录。左下角为收件人设置，选择收件人名单，点击确认验证格式无误后即可在发送状态界面显示出待发送名单，同时可以显示出发送的状态。俗话说，程序里20%是在完成任务，80%是在预防可能出现的问题。这里面的细节还蛮多的，例如发送后在名单未发送完之前不可重复发送，发送完成后整理发送失败名单，可再次点击“发送”等。这些问题的发现与处理，就只能靠程序员明锐的直觉了…目前这款产品还未商用，仅供自娱自乐。</p>
<p>另附一张放风筝的照片，解放双手！
<img src="/2022/04/15/techArt-AutoEmail/p9.jpeg" alt></p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/head.png" alt="Chuanqing Pu"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Chuanqing Pu</p><p class="is-size-6 is-block">An explorer in Engineering</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">2</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/BigdogManLuo" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/BigdogManLuo"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="LinkedIn" href="https://www.linkedin.com/in/chuanqing-pu-943673317/"><i class="fab fa-linkedin"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Articles/"><span class="level-start"><span class="level-item">Articles</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Thoughts/"><span class="level-start"><span class="level-item">Thoughts</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-08-24T23:00:00.000Z">2025-08-25</time></p><p class="title"><a href="/2025/08/25/thoughts-the_nature_of_forecast/">Try to Understand the Nature of Forecasting (1)——Form Geocentric Model to Heliocentric Model</a></p><p class="categories"><a href="/categories/Thoughts/">Thoughts</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-08-05T23:00:00.000Z">2025-08-06</time></p><p class="title"><a href="/2025/08/06/thoughts-AIGC/">论 AIGC 的&quot;图腾&quot;</a></p><p class="categories"><a href="/categories/Articles/">Articles</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-03-06T00:00:00.000Z">2023-03-06</time></p><p class="title"><a href="/2023/03/06/techArt-Code_acc/">Accelerating Your Program Through Coding Skills</a></p><p class="categories"><a href="/categories/Articles/">Articles</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-14T23:00:00.000Z">2022-04-15</time></p><p class="title"><a href="/2022/04/15/techArt-AutoEmail/">裁缝式开发：用MATLAB批量发送一封图文并茂的邮件</a></p><p class="categories"><a href="/categories/Articles/">Articles</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/08/"><span class="level-start"><span class="level-item">August 2025</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Try to Understand" height="28"></a><p class="is-size-7"><span>&copy; 2025 BigdogManLuo</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/BigdogManLuo"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/js/pjax.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>